\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{amsmath, amsfonts, amsthm, mathtools, amssymb}
\usepackage{stmaryrd}
\usepackage{enumerate}
\usepackage{cases}
\usepackage{fancyhdr}
\usepackage{comment}
%\usepackage{xcolor}
\usepackage{tikz}
\usepackage{cases}
\usepackage{listings}
\usepackage{siunitx}
\usepackage[left = 3cm]{geometry}
\usepackage[hidelinks]{hyperref}
\usepackage{subcaption}
\usepackage{gauss}
\newtheorem{satz}{Satz}[section]
\newtheorem{lemma}[satz]{Lemma}
\newtheorem{korollar}[satz]{Korollar}
\newtheorem{proposition}[satz]{Proposition}
\theoremstyle{definition}
\newtheorem{definition}[satz]{Def.}
\newtheorem{axiom}[satz]{Axiom}
\newtheorem{bsp}[satz]{Bsp.}
\newtheorem*{anmerkung}{Anm}
\newtheorem{bemerkung}[satz]{Bem}
\newtheorem*{notatio}{Notation}
\newcommand{\obda}{O.B.d.A. }
\newcommand{\equals}{\Longleftrightarrow}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\intd}{\mathrm{d}}
\newcommand{\Pot}{\operatorname{Pot}}
\newcommand{\mychar}{\operatorname{char}}
\newcommand{\myker}{\operatorname{ker}}
\newcommand{\induktion}[3]
{\begin{proof}\ \\
	\noindent\textbf{Induktionsanfang:}\ #1\\
	\noindent\textbf{Induktionsvoraussetzung:}\ #2\\
	\noindent\textbf{Induktionsschluss:}\ #3
\end{proof}}

\newcommand{\rg}{\operatorname{rg}}
\newcommand{\im}{\operatorname{im}}
\newcommand{\re}{\operatorname{re}}

\newcommand{\ipilayout}[1]
{	
	\pagestyle{fancy}
	\fancyhead[L]{Einführung in die praktische Informatik, Blatt #1}
	\fancyhead[R]{Josua Kugler, Jan Metzger, David Wesner}
	\fancypagestyle{firstpage}{%
		\fancyhf{}
		\lhead{Professor: Peter Bastian\\
			Tutor: Frederick Schenk}
		\rhead{Einführung in die praktische Informatik, Übungsblatt #1\\ David, Jan, Josua}
		\cfoot{\thepage}
	}
\thispagestyle{firstpage}
}

\newcommand{\analayout}[1]
{	
	\pagestyle{fancy}
	\fancyhead[L]{Analysis 1, Blatt #1}
	\fancyhead[R]{Alexander Bryant, Josua Kugler}
	\fancypagestyle{firstpage}{%
		\fancyhf{}
		\lhead{Professor: Ekaterina Kostina\\
			Tutor: Philipp Elja Müller}
		\rhead{Analysis 1, Übungsblatt #1\\ Alexander Bryant, Josua Kugler}
		\cfoot{\thepage}
	}
	\thispagestyle{firstpage}
}
\newcommand{\lalayout}[1]
{	
	\pagestyle{fancy}
	\fancyhead[L]{Lineare Algebra 1, Blatt #1}
	\fancyhead[R]{David Wesner, Josua Kugler}
	\fancypagestyle{firstpage}{%
		\fancyhf{}
		\lhead{Professor: Denis Vogel\\
			Tutor: Marina Savarino}
		\rhead{Lineare Algebra 2, Übungsblatt #1\\ David Wesner, Josua Kugler}
		\cfoot{\thepage}
	}
	\thispagestyle{firstpage}
}

\lstset{
    frame=tb, % draw a frame at the top and bottom of the code block
    tabsize=4, % tab space width
    showstringspaces=false, % don't mark spaces in strings
    numbers=left, % display line numbers on the left
    commentstyle=\color{green}, % comment color
    keywordstyle=\color{blue}, % keyword color
    stringstyle=\color{red} % string color
}
\setlength{\headheight}{25pt}
\begin{document}
\lalayout{0}
\section{Aufgabe 1}

\section{Aufgabe 2}
\begin{enumerate}[(a)]
	\item Jede Matrix $A$ induziert durch $(x,y) \mapsto x^tA\overline{y}$ eine Sesquilinearform. Offensichtlich ist außerdem $A = \overline{A}^t$, daher muss die Sesquilinearform hermitesch sein, $$\overline{h_A(y,x)} = \overline{h_A(y,x)}^t = \overline{y^tA\overline{x}}^t = (\overline{y}^t \overline{A} x)^t = x^t\overline{A}^ty = x^tAy = h_A(x,y).$$ Zudem gilt 
	\begin{align*}
		&\begin{pmatrix}
			x_1 & x_2 & x_3
		\end{pmatrix} \cdot \begin{pmatrix}
			1 & i & 0\\
			-i & 3 & i\\
			0 & -i & 1
		\end{pmatrix} \cdot \begin{pmatrix}
			\overline{x_1}\\
			\overline{x_2}\\
			\overline{x_3}
		\end{pmatrix}\\
		=& \begin{pmatrix}
			x_1 - i x_2 & 3 x_2 + i (x_1 - x_3) & x_3 + i x_2
		\end{pmatrix} \cdot \begin{pmatrix}
			\overline{x_1}\\
			\overline{x_2}\\
			\overline{x_3}
		\end{pmatrix}\\
		=& |x_1|^2 - i \overline{x_1}x_2 + 3|x_2|^2 + i \overline{x_2}(x_1-x_3) + |x_3|^2 + i x_2\overline{x_3}\\
		=& |x_1|^2 + 3|x_2|^2 + |x_3|^2 + i \cdot (-\overline{x_1}x_2 + \overline{x_2}x_1 - \overline{x_2}x_3 + \overline{x_3}x_2)\\
		=& |x_1|^2 + 3|x_2|^2 + |x_3|^2 + i \cdot ((\overline{x_2}x_1) - \overline{(\overline{x_2}x_1)} + (\overline{x_3}x_2) - \overline{(\overline{x_3}x_2)})\\
		=& |x_1|^2 + 3|x_2|^2 + |x_3|^2 + i \cdot (2i \cdot \im(\overline{x_2}x_1) + 2i \cdot \im(\overline{x_3}x_2))\\
		=& \re(x_1)^2 + \im(x_1)^2 + 3\re(x_2)^2 + 3\im(x_2)^2 + \re(x_3)^2 + \im(x_3)^2\\
		 &- 2(\re(x_2)\im(x_1) - \im(x_2)\re(x_1) + \re(x_3)\im(x_2) -\im(x_3)\re(x_2))\\
		=& (\re(x_2) - \im(x_1))^2 + (\im(x_2) + \re(x_1))^2 + (\re(x_3) - \im(x_2))^2 + (\im(x_3) + \re(x_2))^2 + |x_2|^2\\
		\geq&0
	\end{align*} woraus die positive Definitheit folgt.
	\item Als Ausgangsbasis für die Gram-Schmidt-Orthogonalisierung nehmen wir die kanonische Basis des $\C^3$, $$\{v_1, v_2, v_3\} \left\{\begin{pmatrix}
		1\\0\\0
	\end{pmatrix}, \begin{pmatrix}
		0\\1\\0
	\end{pmatrix}, \begin{pmatrix}
		0\\0\\1
	\end{pmatrix}\right\}.$$ Wegen $h_A(v_1, v_1) = 1$ ist sofort $w_1 = v_1$. Dann berechnen wir $$w_2' = v_2 - h_A(v_2, w_1)w_1 = v_2 + i\cdot v_1 = \begin{pmatrix}
		i\\
		1\\
		0
	\end{pmatrix}$$
	und $$w_2 = \frac{w_2'}{\sqrt{h_A(w_2', w_2')}} = \frac{w_2'}{\sqrt{2}} = \frac{\sqrt{2}}{2}\cdot \begin{pmatrix}
		i\\
		1\\
		0
	\end{pmatrix}$$
	Damit kommt man auf $$w_3' = v_3 - h_A(v_3, w_1)w_1 - h_A(v_3, w_2)w_2 = v_3 - 0\cdot w_1 + \frac{\sqrt{2}}{2}\cdot i \cdot w_2 = \begin{pmatrix}
		-\frac{1}{2}\\
		\frac{i}{2}\\
		1
	\end{pmatrix}$$
	und schließlich ist $$w_3 = \frac{w_3'}{\sqrt{h_A(w_3', w_3')}} = \frac{w_2'}{\sqrt{\frac{1}{2}}} = \frac{\sqrt{2}}{2}\cdot \begin{pmatrix}
		-1\\
		i\\
		2
	\end{pmatrix}$$
	Folglich ist $$\underline{w} = \{w_1, w_2, w_3\} = \left\{\begin{pmatrix}
		1\\0\\0
	\end{pmatrix}, \frac{\sqrt{2}}{2}\cdot \begin{pmatrix}
		i\\
		1\\
		0
	\end{pmatrix}, \frac{\sqrt{2}}{2}\cdot \begin{pmatrix}
		-1\\
		i\\
		2
	\end{pmatrix}\right\}$$ eine Orthonormalbasis von $(\C^3, h_A)$
	\item Dafür bestimmen wir zunächst die Darstellungsmatrix von $B$ bzgl. einer Orthonormalbasis von $(\C^3, h_A)$ und wählen dafür $\underline{w}$. Es gilt $$T = \begin{pmatrix}
		1 & \frac{\sqrt{2}}{2} i & -\frac{\sqrt{2}}{2}\\[0.5em]
		0 & \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} i\\[0.5em]
		0 & 0 & \sqrt{2}
	\end{pmatrix}.$$ Nun berechnen wir noch $T^{-1}$.
	\begin{align*}
		\begin{gmatrix}[p]
			1 & \frac{\sqrt{2}}{2} i & -\frac{\sqrt{2}}{2}\\
			0 & \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} i\\
			0 & 0 & \sqrt{2}
			\rowops
			\add[-i]{1}{0}
		\end{gmatrix} &\left|
		\begin{gmatrix}[p]
			1 & 0 & 0\\
			0 & 1 & 0\\
			0 & 0 & 1
			\rowops
			\add[-i]{1}{0}
		\end{gmatrix}\right.\\
		\begin{gmatrix}[p]
			1 & 0 & 0\\
			0 & \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} i\\
			0 & 0 & \sqrt{2}
			\rowops
			\mult{1}{\cdot \frac{2}{\sqrt{2}}}
			\mult{2}{\cdot \frac{1}{\sqrt{2}}}
		\end{gmatrix} &\left|
		\begin{gmatrix}[p]
			1 & -i & 0\\
			0 & 1 & 0\\
			0 & 0 & 1
			\rowops
			\mult{1}{\cdot \frac{2}{\sqrt{2}}}
			\mult{2}{\cdot \frac{1}{\sqrt{2}}}
		\end{gmatrix}\right.\\
		\begin{gmatrix}[p]
			1 & 0 & 0\\
			0 & 1 & i\\
			0 & 0 & 1
			\rowops
			\add[-i]{2}{1}
		\end{gmatrix} &\left|
		\begin{gmatrix}[p]
			1 & -i & 0\\
			0 & \sqrt{2}& 0\\
			0 & 0 & \frac{\sqrt{2}}{2}
			\rowops
			\add[-i]{2}{1}
		\end{gmatrix}\right.\\
		\begin{gmatrix}[p]
			1 & 0 & 0\\
			0 & 1 & 0\\
			0 & 0 & 1
		\end{gmatrix} &\left|
		\begin{gmatrix}[p]
			1 & -i & 0\\
			0 & \sqrt{2}& -i \frac{\sqrt{2}}{2}\\
			0 & 0 & \frac{\sqrt{2}}{2}
		\end{gmatrix}\right.\\
	\end{align*}
	Folglich ist die Darstellungsmatrix von $B$ bzgl. $\underline{w}$
	$$T^{-1} \cdot B \cdot T = \begin{pmatrix}
		1 & -i & 0\\[0.5em]
		0 & \sqrt{2}& -i \frac{\sqrt{2}}{2}\\[0.5em]
		0 & 0 & \frac{\sqrt{2}}{2}
	\end{pmatrix} \cdot \begin{pmatrix}
		2 & -2i & -i\\[0.5em]
		0 & 0 & -1\\[0.5em]
		0 & 0 & 2i
	\end{pmatrix} \cdot \begin{pmatrix}
		1 & \frac{\sqrt{2}}{2} i & -\frac{\sqrt{2}}{2}\\[0.5em]
		0 & \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} i\\[0.5em]
		0 & 0 & \sqrt{2}
	\end{pmatrix} = \begin{pmatrix}
		2 & 0 & 0\\[0.5em]
		0 & 0 & 0\\[0.5em]
		0 & 0 & 2i
	\end{pmatrix}$$
	Die dazu adjungierte Matrix ist also die Darstellungsmatrix der adjungierten Abbildung zu $B\cdot$.
	Es gilt
	$$\begin{pmatrix}
		2 & 0 & 0\\
		0 & 0 & 0\\
		0 & 0 & 2i
	\end{pmatrix} \cdot \begin{pmatrix}
		2 & 0 & 0\\
		0 & 0 & 0\\
		0 & 0 & -2i
	\end{pmatrix} = \begin{pmatrix}
		4 & 0 & 0\\
		0 & 0 & 0\\
		0 & 0 & 4
	\end{pmatrix} = \begin{pmatrix}
		2 & 0 & 0\\
		0 & 0 & 0\\
		0 & 0 & -2i
	\end{pmatrix} \cdot \begin{pmatrix}
		2 & 0 & 0\\
		0 & 0 & 0\\
		0 & 0 & 2i
	\end{pmatrix}$$ und folglich ist $B\cdot $ normal bezüglich $(V, h_A)$.
	Mit dem Standardskalarprodukt ist $B \cdot$ nicht normal, da die Standardbasis eine Orthonormalbasis darstellt und $$B \cdot B^* \neq B^* \cdot B$$
	\item $\chi_\text{char} = (\lambda - 2)\cdot \lambda \cdot (\lambda - 2i) \implies \{2, 0, 2i\}$ sind Eigenwerte von $B$. Der Eigenraum zu $\lambda = 2$ ist $$\operatorname{Lin} \begin{pmatrix}
		1\\ 0 \\ 0
	\end{pmatrix},$$ zu $\lambda = 0$ $$\operatorname{Lin} \begin{pmatrix}
		i\\1\\0
	\end{pmatrix}$$ und zu $\lambda = 2i$ $$\operatorname{Lin} \begin{pmatrix}
		1\\ -i\\ -2
	\end{pmatrix}.$$ Da die Eigenräume alle nur eindimensional sind genügt es, $$h_A(\begin{pmatrix}
		1\\ 0 \\ 0
	\end{pmatrix}, \begin{pmatrix}
		i\\1\\0
	\end{pmatrix}) = 0,$$ $$h_A(\begin{pmatrix}
		1\\ -i\\ -2
	\end{pmatrix}, \begin{pmatrix}
		i\\1\\0
	\end{pmatrix}) = 0$$ und $$h_A(\begin{pmatrix}
		1\\ 0 \\ 0
	\end{pmatrix}, \begin{pmatrix}
		1\\ -i\\ -2
	\end{pmatrix}) = 0$$ nachzurechnen.
	\item Wir rechnen es wieder analog zur (c) in einer Orthonormalbasis von $(V, h_A)$ nach und sehen
	$$\begin{pmatrix}
		2 & 0 & 0\\
		0 & 0 & 0\\
		0 & 0 & 2i
	\end{pmatrix} \neq \begin{pmatrix}
		2 & 0 & 0\\
		0 & 0 & 0\\
		0 & 0 & -2i
	\end{pmatrix}, $$ folglich ist $B\cdot $ nicht selbstadjungiert.
\end{enumerate}
\section{Aufgabe 3} 

\end{document}